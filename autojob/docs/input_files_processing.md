# File: autojob/src/preprocessing/input_files_processing.py

This Python script, `input_files_processing.py`, is designed for preprocessing input JSON files related to job postings. It consists of two main functions:

1. **split_input_postings(INPUT_FILES_DIR, ALL_POSTINGS_DIR):**
    - This function takes as input the directory containing the input JSON files (`INPUT_FILES_DIR`) and the directory where the individual job postings will be stored (`ALL_POSTINGS_DIR`).
    - It splits the input JSON files into individual job postings with unique filenames based on the 'id' field. The output filenames are generated by appending a count to the original 'id', ensuring uniqueness.
    - The processed job postings are saved as separate JSON files in the specified output directory.

2. **update_job_posts(ALL_POSTINGS_DIR, JOB_POSTS_DIR):**
    - This function is responsible for updating job postings based on the latest posting date and URL.
    - It takes the directory containing all job postings (`ALL_POSTINGS_DIR`) and the directory where the updated job postings will be stored (`JOB_POSTS_DIR`) as input.
    - For each job posting, it looks for other versions (indicated by "_0.json") and identifies the latest posting date and URL among them.
    - The script then updates the original job posting file with the latest URL. If no URL is found, it copies the existing file.
    - The result is a set of updated job postings with the latest information stored in the specified output directory.

The script uses the `os`, `json`, `datetime`, and `dateutil.parser` libraries for file and date operations. Additionally, it employs the `textacy.preprocessing` module for text normalization. The functions are documented with comments for clarity and ease of understanding.
